{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¦€  Aiven Setup\n",
    "\n",
    "\n",
    "\n",
    "The setup starts an **Apache Kafke** and a **postgreSQL** database used in the other notebooks\n",
    "To execute all the steps on top of Aiven.io instances, please register on the [console](https://console.aiven.io?utm_source=github&utm_medium=organic&utm_campaign=blog_art&utm_content=post) \n",
    "\n",
    "---\n",
    "\n",
    "## Set the Environment \n",
    "\n",
    "### Set Variables\n",
    "\n",
    "The following global variables will define the kafka instance, change with care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p config\n",
    "echo \"export FOLDER_NAME=kafkacerts\n",
    "export PROJECT_NAME=my-test-name\n",
    "export CLOUD=google-europe-west3\n",
    "export KAFKA_NAME=kafka-pywebconf\n",
    "export POSTGRES_NAME=pg-pywebconf\n",
    "export AIVEN_PLAN_NAME=business-4\n",
    "export TOPIC_NAME=pizzas\n",
    "export PG_USER=new_pg_user\n",
    "export PG_PWD=NewPWD123\n",
    "export KAFKA_TIMEOUT=5000\" > config/profile_info.sh\n",
    "\n",
    "echo \"\" > config/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Aiven Kafka environment\n",
    "\n",
    "For this demo we'll create a Kafka environment in [Aiven.io](https://aiven.io/) in order to follow these steps you would need to have a valid login to Aiven.io console and have a token already generated. In the below script change the `<EMAIL>` and `<TOKEN>` fields to match yours. Let's login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "mkdir -p ~/.config/aiven\n",
    "echo '{\n",
    "    \"auth_token\": \"<INSERT_TOKEN_HERE>\",\n",
    "    \"user_email\": \"<INSERT_EMAIL_HERE>\"\n",
    "}' > ~/.config/aiven/aiven-credentials.json\n",
    "\n",
    "pip install aiven-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the login we can create our kafka instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source config/profile_info.sh\n",
    "\n",
    "avn service create  -p $AIVEN_PLAN_NAME \\\n",
    "                    -t kafka $KAFKA_NAME \\\n",
    "                    --cloud $CLOUD \\\n",
    "                    --project $PROJECT_NAME \\\n",
    "                    -c kafka_rest=true \\\n",
    "                    -c kafka.auto_create_topics_enable=true \\\n",
    "                    -c schema_registry=true \\\n",
    "                    -c kafka_connect=true\n",
    "\n",
    "avn service create $POSTGRES_NAME -t pg -p startup-4 --cloud $CLOUD --project $PROJECT_NAME\n",
    "\n",
    "avn service wait $KAFKA_NAME --project $PROJECT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Kafka certificates and service URI. We'll use the certificates to connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download all certificates\n",
    "source config/profile_info.sh\n",
    "\n",
    "mkdir -p kafkacerts\n",
    "avn service user-creds-download $KAFKA_NAME --project $PROJECT_NAME -d $FOLDER_NAME --username avnadmin\n",
    "\n",
    "# get KAFKA URL and write to disk as `HOSTNAME and PORT`\n",
    "avn service get $KAFKA_NAME --project=$PROJECT_NAME --format '{service_uri}' | awk  -F':' '{print \"hostname = \\\"\"$1\"\\\"\\nport = \"$2\"\\ncert_folder = \\\"\"FOLDER_NAME\"\\\"\\ntopic_name = \\\"\"TOPIC_NAME\"\\\"\\npg_user = \\\"\"PG_USER\"\\\"\\npg_pwd = \\\"\"PG_PWD\"\\\"\\ntimeout_ms = \"KAFKA_TIMEOUT\"\"}' FOLDER_NAME=$FOLDER_NAME TOPIC_NAME=$TOPIC_NAME PG_USER=$PG_USER PG_PWD=$PG_PWD KAFKA_TIMEOUT=$KAFKA_TIMEOUT > config/kafka_config.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **PostgreSQL User**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source config/profile_info.sh\n",
    "#avn service create $POSTGRES_NAME -t pg -p startup-4 --cloud $CLOUD --project $PROJECT_NAME\n",
    "\n",
    "avn service wait $POSTGRES_NAME --project $PROJECT_NAME\n",
    "avn service get $POSTGRES_NAME --project=$PROJECT_NAME --format '{service_uri_params}' > config/pg_config.json\n",
    "avn service user-create $POSTGRES_NAME --project $PROJECT_NAME --username $PG_USER\n",
    "avn service user-password-reset $POSTGRES_NAME --project $PROJECT_NAME --username $PG_USER --new-password $PG_PWD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's parse the fields and create the Kafka Connect Connector config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from config.kafka_config import *\n",
    "with open('config/pg_config.json') as json_file:\n",
    "    data = json.loads(json_file.read().replace(\"'\",'\"'))\n",
    "    pg_dbname = data['dbname']\n",
    "    pg_host = data['host']\n",
    "    pg_port = data['port']\n",
    "    pg_super_user = data['user']\n",
    "    pg_super_pwd = data['password']\n",
    "\n",
    "connect_setup = {\n",
    "    \"name\": \"sink_kafka_pg\",\n",
    "    \"connector.class\": \"io.aiven.connect.jdbc.JdbcSinkConnector\",\n",
    "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n",
    "    \"topics.regex\": topic_name+\"_schema\",\n",
    "    \"connection.url\": \"jdbc:postgresql://\"+pg_host+\":\"+pg_port+\"/\"+pg_dbname+\"?sslmode=require\",\n",
    "    \"connection.user\": pg_user,\n",
    "    \"connection.password\": pg_pwd,\n",
    "    \"auto.create\": \"true\"\n",
    "}\n",
    "\n",
    "f = open(\"config/kafka_connect_setup.txt\", \"w\")\n",
    "f.write(json.dumps(connect_setup, indent=4, sort_keys=True))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to postgress and grant access to newly created user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname=pg_dbname,\n",
    "                        user=pg_super_user,\n",
    "                        host=pg_host,\n",
    "                        port=pg_port,\n",
    "                        password=pg_super_pwd,\n",
    "                        sslmode='require')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE defaultdb TO \"+pg_user+\";\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA public TO \"+pg_user+\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
